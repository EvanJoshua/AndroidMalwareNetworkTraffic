/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package neuralnetwork;

import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.util.stream.IntStream;

/**
 *
 * @author asus
 */
public class NeuralNetwork {

    public static double LEARNING_RATE = 0.01;
    final static int NUMB_OF_INPUT_NEURONS = Driver.trainingData[0][0].length;
    final static int NUMB_OF_OUTPUT_NEURONS = 3;
    public static int numbOfHiddenNeurons = 4;
    public static Layer[] layers = new Layer[Layer.LayerType.values().length];
    public static int truePositive = 0;
    public static int trueNegative = 0;
    public static int falsePositive = 0;
    public static int falseNegative = 0;
    public static int benign = 0;
    public static int predictBenign = 0;
    public static int predictGeneralMalware = 0;
    public static int predictAdware = 0;
    public static int total = 0;

    public NeuralNetwork() throws FileNotFoundException, IOException {
        layers[0] = new Layer(this, Layer.LayerType.I);
        layers[1] = new Layer(this, Layer.LayerType.H);
        layers[2] = new Layer(this, Layer.LayerType.O);
    }

    public NeuralNetwork forwardprop(double input[], double targetResult[]) {
        total++;
        for (int i = 0; i < layers.length; i++) {
            switch (layers[i].getLayerType()) {
                case I:
                    for (int j = 0; j < layers[i].getNeurons().length; j++) {
                        layers[i].getNeurons()[j].setOOUT(input[j]);
                    }
                    break;
                case H:
                    for (int j = 0; j < layers[i].getNeurons().length; j++) {
                        double weightedSum = 0;
                        for (int k = 0; k < layers[i].getNeurons()[0].getWeights().length; k++) {
                            weightedSum += layers[i].getNeurons()[j].getWeights()[k] * layers[i - 1].getNeurons()[k].getOOUT();
                        }
                        weightedSum += 1;
                        layers[i].getNeurons()[j].sigmoidFunction(weightedSum);
                    }
                    break;
                case O:
                    double weightedSum = 0;
                    double arrayWeightedSum[] = new double[layers[i].getNeurons().length];
                    int max = 0;
                    int targetIndex = 0;
                    double result[] = new double[layers[i].getNeurons().length];
                    //for untuk jumlah neuron di output layer, hitung nilai Z
                    for (int j = 0; j < layers[i].getNeurons().length; j++) {
                        weightedSum = 0;
                        //for untuk banyak neuron di hidden layer
                        for (int k = 0; k < layers[i].getNeurons()[j].getWeights().length; k++) {
                            weightedSum += layers[i].getNeurons()[j].getWeights()[k] * layers[i - 1].getNeurons()[k].getOOUT();
                        }

                        arrayWeightedSum[j] = weightedSum + 1;
                    }

                    //for untuk cari target index nya berapa dan prediksi nya apa, for sesuai jumlah neuron di output layer
                    for (int j = 0; j < layers[i].getNeurons().length; j++) {
                        layers[i].getNeurons()[j].softmaxFunction(j, arrayWeightedSum);
                        if (layers[i].getNeurons()[j].getOOUT() > layers[i].getNeurons()[max].getOOUT()) {
                            max = j;
                        }
                        if (targetResult[j] == 1) {
                            targetIndex = j;
                        }
                        result[j] = layers[i].getNeurons()[j].getOOUT();
                    }

                    if ((max == targetIndex)) {
                        if (max == benign) {
                            trueNegative++;
                        } else {
                            truePositive++;
                        }
                    } else if (targetIndex == benign) {
                        falseNegative++;
                    } else {
                        falsePositive++;
                    }

                    switch (max) {
                        case 0:
                            predictBenign++;
                            break;
                        case 1:
                            predictAdware++;
                            break;
                        case 2:
                            predictGeneralMalware++;
                            break;
                        default:
                            break;
                    }
                    break;
                default:
                    break;
            }
        }
        return this;
    }

    public NeuralNetwork backpropError(double targetResult[]) throws FileNotFoundException, UnsupportedEncodingException {
        Neuron[] iNeuron = layers[0].getNeurons();
        Neuron[] hNeuron = layers[1].getNeurons();
        Neuron[] oNeuron = layers[2].getNeurons();

        //update weight hidden-output, for neuron di output layer
        for (int i = 0; i < layers[layers.length - 1].getNeurons().length; i++) {
            newWeightsHiddenOutput(hNeuron, oNeuron[i], (int) targetResult[i], i);
        }

        //update weight input-hidden, for neuron di hidden layer
        for (int i = 0; i < numbOfHiddenNeurons; i++) {
            newWeightsInputHidden(iNeuron, hNeuron[i], oNeuron, i);
        }
        return this;
    }

    public void newWeightsHiddenOutput(Neuron neuronHidden[], Neuron neuronOutput, int targetResult, int index) {
        double weights[] = new double[neuronOutput.getWeights().length];
        double derivativeWeight = 0;
        //for jumlah hidden neuron, index = neuron di output layer
        for (int i = 0; i < neuronOutput.getWeights().length; i++) {
            derivativeWeight = derivativeErrorChainRuleHiddenOutput(index, neuronHidden[i], neuronOutput, targetResult);
            weights[i] = neuronOutput.getWeights()[i] - (LEARNING_RATE * derivativeWeight);
        }
        neuronOutput.setWeights(weights);
    }

    public double derivativeErrorChainRuleHiddenOutput(int index, Neuron neuronHidden, Neuron neuronOutput, int targetResult) {
        return derivativeCrossEntropy(targetResult, neuronOutput) * derivativeSoftmax(index) * derivativeInputToOutputWeight(neuronHidden);
    }

    public double derivativeCrossEntropy(double targetResult, Neuron neuronOutput) {
        double result = -1 * ((targetResult / neuronOutput.getOOUT()) + ((targetResult - 1) * (1 / (1 - neuronOutput.getOOUT()))));
        neuronOutput.setDerivativeCrossEntropy(result);
        return result;
    }

    public double derivativeSoftmax(int index) {
        double pembilang = 0;
        double penyebut = 0;
        double zigmaEXP = 0;
        double result = 0;
        Neuron neuron = null;
        //for untuk banyak neuron di output layer
        for (int i = 0; i < layers[layers.length - 1].getNeurons().length; i++) {
            neuron = layers[layers.length - 1].getNeurons()[i];
            penyebut += Math.exp(neuron.getOIN());

            if (i != index) {
                zigmaEXP += Math.exp(neuron.getOIN());
            }
        }

        penyebut = Math.pow(penyebut, 2);
        neuron = layers[layers.length - 1].getNeurons()[index];
        pembilang = Math.exp(neuron.getOIN()) * zigmaEXP;
        result = pembilang / penyebut;
        neuron.setDerivativeSoftmax(result);
        return result;
    }

    public double derivativeInputToOutputWeight(Neuron neuronHidden) {
        return neuronHidden.getOOUT();
    }

    public void newWeightsInputHidden(Neuron neuronInput[], Neuron neuronHidden, Neuron neuronOutput[], int index) {
        double weights[] = new double[neuronHidden.getWeights().length];
        double derivativeWeight = 0;
        //for neuron di input layer
        for (int i = 0; i < neuronHidden.getWeights().length; i++) {
            derivativeWeight = derivativeErrorChainRuleInputHidden(neuronInput[i], neuronHidden, neuronOutput, index);
            weights[i] = neuronHidden.getWeights()[i] - (LEARNING_RATE * derivativeWeight);
        }
        neuronHidden.setWeights(weights);
    }

    public static double getLEARNING_RATE() {
        return LEARNING_RATE;
    }

    public static void setLEARNING_RATE(double LEARNING_RATE) {
        NeuralNetwork.LEARNING_RATE = LEARNING_RATE;
    }

    public static int getTruePositive() {
        return truePositive;
    }

    public static void setTruePositive(int truePositive) {
        NeuralNetwork.truePositive = truePositive;
    }

    public static int getTrueNegative() {
        return trueNegative;
    }

    public static void setTrueNegative(int trueNegative) {
        NeuralNetwork.trueNegative = trueNegative;
    }

    public static int getFalsePositive() {
        return falsePositive;
    }

    public static void setFalsePositive(int falsePositive) {
        NeuralNetwork.falsePositive = falsePositive;
    }

    public static int getFalseNegative() {
        return falseNegative;
    }

    public static void setFalseNegative(int falseNegative) {
        NeuralNetwork.falseNegative = falseNegative;
    }

    public static int getBenign() {
        return benign;
    }

    public static void setBenign(int benign) {
        NeuralNetwork.benign = benign;
    }

    public static int getPredictBenign() {
        return predictBenign;
    }

    public static void setPredictBenign(int predictBenign) {
        NeuralNetwork.predictBenign = predictBenign;
    }

    public static int getPredictGeneralMalware() {
        return predictGeneralMalware;
    }

    public static void setPredictGeneralMalware(int predictGeneralMalware) {
        NeuralNetwork.predictGeneralMalware = predictGeneralMalware;
    }

    public static int getPredictAdware() {
        return predictAdware;
    }

    public static void setPredictAdware(int predictAdware) {
        NeuralNetwork.predictAdware = predictAdware;
    }

    public static int getTotal() {
        return total;
    }

    public static void setTotal(int total) {
        NeuralNetwork.total = total;
    }

    public double derivativeErrorChainRuleInputHidden(Neuron neuronInput, Neuron neuronHidden, Neuron neuronOutput[], int index) {
        double result = 0;
        result = derivativeErrorHiddenLayer(neuronOutput, index) * derivativeSigmoid(neuronHidden) * derivativeInputLayer(neuronInput);
        return result;
    }

    public double derivativeErrorHiddenLayer(Neuron neuronOutput[], int index) {
        double error = 0;
        for (int i = 0; i < neuronOutput.length; i++) {
            error += neuronOutput[i].getDerivativeCrossEntropy() * neuronOutput[i].getDerivativeSoftmax() * neuronOutput[i].getWeights()[index];
        }
        return error;
    }

    public double derivativeSigmoid(Neuron neuronHidden) {
        double result = 0;
        double sigmoidResult = sigmoid(neuronHidden.getOIN());
        result = sigmoidResult * (1 - sigmoidResult);
        return result;
    }

    public double sigmoid(double weightedSum) {
        return 1.0 / (1 + Math.exp(-1.0 * weightedSum));
    }

    public double derivativeInputLayer(Neuron neuronInput) {
        return neuronInput.getOOUT();
    }

    public double errorCrossEntropy(double[] targetResult, double[] result) {
        double crossEntropy = 0;
        for (int i = 0; i < targetResult.length; i++) {
            crossEntropy += (targetResult[i] * Math.log(result[i])) + ((1 - targetResult[i]) * Math.log(1 - result[i]));
        }
        crossEntropy = -1 * crossEntropy;
        return crossEntropy;
    }

    public int getNumbOfHiddenNeurons() {
        return numbOfHiddenNeurons;
    }

    public Layer[] getLayers() {
        return layers;
    }
}
